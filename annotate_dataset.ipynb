{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import OrderedDict\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test-v2.0.en.json\") as f:\n",
    "    f_ = json.load(f, object_hook=OrderedDict)\n",
    "with open(\"test-v2.0.cs.raw.json\") as f:\n",
    "    f = json.load(f, object_hook=OrderedDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _show_dialog(tooltip, text, callback):\n",
    "    print(tooltip)\n",
    "    u = widgets.Textarea(\n",
    "        value=text,\n",
    "        description='Correct:',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(width='100%', height='300px')\n",
    "    )\n",
    "    #w = widgets.Text(\n",
    "    #    value=context,\n",
    "    #    description='Paste here',\n",
    "    #    disabled=False,\n",
    "    #    layout=widgets.Layout(width='100%', height='50px')\n",
    "    #)\n",
    "\n",
    "    button = widgets.Button(description=\"Next\")\n",
    "    button._dirtyhack = u\n",
    "    output = widgets.Output()\n",
    "\n",
    "    display(u)\n",
    "    #display(w)\n",
    "    display(button, output)\n",
    "    button.on_click(callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i, j = 0, 0\n",
    "#state = \"context\"\n",
    "\n",
    "def process_next(i, j, state):\n",
    "    \n",
    "    if state == 'context':\n",
    "        annotate_context(i, j, state)\n",
    "    elif state.startswith('question'):\n",
    "        q = int(state.split(\"_\")[1])\n",
    "        annotate_question(i, j, q)\n",
    "    elif state.startswith('answers'):\n",
    "        q = int(state.split(\"_\")[1])\n",
    "#         a = int(state.split(\"_\")[2])\n",
    "        annotate_answers(i, j, q)\n",
    "\n",
    "def annotate_context(i, j, state):\n",
    "    print(i, \"/\", len(f['data']), \", \", j, \"/\", len(f['data'][i]['paragraphs']))\n",
    "    context = f['data'][i]['paragraphs'][j]['context']\n",
    "    tooltip = \"Please correct this text:\\nOriginal: %s\" % f_['data'][i]['paragraphs'][j]['context']\n",
    "    def callback(w):\n",
    "        f['data'][i]['paragraphs'][j]['context'] = w._dirtyhack.value\n",
    "        clear_output()\n",
    "#             print(w._dirtyhack.value)\n",
    "        process_next(i, j, state=\"question_0\")\n",
    "    _show_dialog(tooltip, context, callback)\n",
    "\n",
    "def annotate_question(i, j, q):\n",
    "    question = f['data'][i]['paragraphs'][j]['qas'][q]['question']\n",
    "    question_en = f_['data'][i]['paragraphs'][j]['qas'][q]['question']\n",
    "    tooltip = \"Please correct this question:\\nOriginal:%s\" % (question_en)\n",
    "    \n",
    "    def callback(w):\n",
    "        f['data'][i]['paragraphs'][j]['qas'][q]['question'] = w._dirtyhack.value\n",
    "        clear_output()\n",
    "        process_next(i, j, state=\"answers_%d\" % q)\n",
    "        return  # TODO\n",
    "    \n",
    "    _show_dialog(tooltip, text=question, callback=callback)\n",
    "\n",
    "\n",
    "def annotate_answers(i, j, q):  # TODO: show original span\n",
    "    print(\"Please provide exactly 4 answers to the question.\")\n",
    "    \n",
    "    if f['data'][i]['paragraphs'][j]['qas'][q]['is_impossible']:\n",
    "        # TODO: edit plausible answers\n",
    "        print(\"Warning: impossible answer\")\n",
    "    \n",
    "    question = f['data'][i]['paragraphs'][j]['qas'][q]['question']\n",
    "    question_en = f_['data'][i]['paragraphs'][j]['qas'][q]['question']\n",
    "    context = f['data'][i]['paragraphs'][j]['context']  # now corrected\n",
    "    answer = f_['data'][i]['paragraphs'][j]['qas'][q]['answers']\n",
    "    tooltip = \"Please mark answer 1 with (text)@@@(answer)@@@(text)\\nQuestion:%s\\nOriginal:%s\\nAnswer:%s\" % (question, question_en, answer)\n",
    "    \n",
    "    def callback(w):\n",
    "        # TODO: find span marked by user\n",
    "        start_idx = w._dirtyhack.value.find(\"@@@\") + 3\n",
    "        end_idx = w._dirtyhack.value.find(\"@@@\", start_idx+3)\n",
    "        \n",
    "        if start_idx == -1 or end_idx == -1:\n",
    "            w._dirtyhack.value = f['data'][i]['paragraphs'][j]['context']\n",
    "            print(\"Invalid answer! Please try again, context was reset.\")\n",
    "            return\n",
    "        \n",
    "        if not hasattr(w, \"answer_idx\"):\n",
    "            answer_idx = 0\n",
    "        else:\n",
    "            answer_idx = w.answer_idx\n",
    "        # TODO: save ith answer\n",
    "        answer_idx += 1\n",
    "        w.answer_idx = answer_idx\n",
    "        # TODO: show i+1th dialog\n",
    "        if answer_idx < 4:\n",
    "            # TODO: say which answer it is\n",
    "            print(\"Editing answer %d\" % answer_idx)\n",
    "            w._dirtyhack.value = f['data'][i]['paragraphs'][j]['context']\n",
    "            #_show_dialog(tooltip, text=context, callback=callback)\n",
    "        else:\n",
    "            clear_output()\n",
    "            # TODO: loop answer\n",
    "            if q + 1 < len(f['data'][i]['paragraphs'][j]['qas']):\n",
    "                process_next(i, j, \"question_%d\" % (q + 1))\n",
    "            elif j + 1 < len(f['data'][i]['paragraphs']):\n",
    "                process_next(i, j+1, \"context\")\n",
    "            elif i + 1 < len(f['data']):\n",
    "                process_next(i+1, 0, \"context\")\n",
    "            else:\n",
    "                print(\"Done!\")\n",
    "        \n",
    "        #print(start_idx, end_idx)\n",
    "        #print(w._dirtyhack.value[start_idx:end_idx])        \n",
    "        return\n",
    "    \n",
    "    _show_dialog(tooltip, text=context, callback=callback)\n",
    "    print(\"Editing answer %d\" % 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide exactly 4 answers to the question.\n",
      "Please mark answer 1 with (text)@@@(answer)@@@(text)\n",
      "Question:Kdy byli Normani v Normandii?\n",
      "Original:When were the Normans in Normandy?\n",
      "Answer:[OrderedDict([('text', '10th and 11th centuries'), ('answer_start', 94)]), OrderedDict([('text', 'in the 10th and 11th centuries'), ('answer_start', 87)]), OrderedDict([('text', '10th and 11th centuries'), ('answer_start', 94)]), OrderedDict([('text', '10th and 11th centuries'), ('answer_start', 94)])]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54f3f53e7e64e209217a3aa9094dcb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='Normané ( Norman : Nourmands ; francouzština : Normandi ; latina : Normanni ) byli lidé, kteří…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63c26fb57304a88a784094945cf3251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Next', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f785a217d5db4a0e8fdf91e4f08f2b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Editing answer 0\n"
     ]
    }
   ],
   "source": [
    "process_next(i=0, j=0, state=\"context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Normané ( Norman : Nourmands ; francouzština : Normandi ; latina : Normané ) byli lidé, kteří v 10. a 11. století dali své jméno Normandii , oblasti ve Francii . Byli potomky severských nájezdníků a pirátů z Dánska, Islandu a Norska, kteří pod vedením svého vůdce Rolla souhlasili s přísahou věrnosti králi Karlu III. ze Západní Francie. Prostřednictvím generací asimilace a mísení s původními Franky a Římsko-Gaulishskými populacemi by jejich potomci postupně splynuli s karolínskými kulturami Západní Francie. Výrazná kulturní a etnická identita Normanů se objevila zpočátku v první polovině 10. století a v následujících stoletích se dále vyvíjela .'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['data'][0]['paragraphs'][0]['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_['data'][0]['paragraphs'][0]['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(OrderedDict([('question', 'V jaké zemi se nachází Normandie?'),\n",
       "              ('id', '56ddde6b9a695914005b9628'),\n",
       "              ('answers',\n",
       "               [OrderedDict([('text', 'Francii'), ('answer_start', 152)]),\n",
       "                OrderedDict([('text', 'Francii'), ('answer_start', 152)]),\n",
       "                OrderedDict([('text', 'Francii'), ('answer_start', 152)]),\n",
       "                OrderedDict([('text', 'Francii'), ('answer_start', 152)])]),\n",
       "              ('is_impossible', False)]),\n",
       " OrderedDict([('plausible_answers',\n",
       "               [OrderedDict([('text', '10. století'),\n",
       "                             ('answer_start', 594)])]),\n",
       "              ('question', 'Kdy se objevila identita Franků?'),\n",
       "              ('id', '5ad39d53604f3c001a3fe8d4'),\n",
       "              ('answers', []),\n",
       "              ('is_impossible', True)]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['data'][0]['paragraphs'][0]['qas'][0], f['data'][0]['paragraphs'][0]['qas'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To annotate: 111 questions, 444 answers in 10 contexts\n"
     ]
    }
   ],
   "source": [
    "n_contexts = len(f['data'])\n",
    "n_questions = sum(len(f_['data'][i]['paragraphs'][0]['qas']) for i in range(len(f_['data'])))\n",
    "n_answers = n_questions * 4\n",
    "print(\"To annotate: %d questions, %d answers in %d contexts\" % (n_questions, n_answers, n_contexts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test-v2.0.cs.annot.json\", \"w\") as fp:\n",
    "    json.dump(f, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In training : 412 questions, 1648 answers in 35 contexts\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15440"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3860 * 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### obtain all questions (EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../squad2/train-v1.1.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d1dd440ec909>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msquad_questions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../squad2/train-v1.1.json\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../squad2/train-v1.1.json'"
     ]
    }
   ],
   "source": [
    "squad_questions = []\n",
    "\n",
    "with open(\"../squad2/train-v2.0.json\") as fp:\n",
    "    train = json.load(fp)\n",
    "for i in train['data']:\n",
    "    for j in i['paragraphs']:\n",
    "        # one context\n",
    "        context = j['context']\n",
    "        for k in j['qas']:\n",
    "            # one question\n",
    "            question = k['question']\n",
    "            squad_questions.append(question)\n",
    "\n",
    "with open(\"../squad2/questions.txt\", \"w\") as fp:\n",
    "    for question in squad_questions:\n",
    "        fp.write(question + \"\\n\")\n",
    "print(\"Wrote %d questions\" % len(squad_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "tokenize = TreebankWordTokenizer().tokenize\n",
    "\n",
    "def hood(context, idx):\n",
    "    text = context[idx-80:idx+80]\n",
    "    start = text.find(\" \")\n",
    "    end = text.rfind(\" \", start + 1)\n",
    "    text = text[start:end]\n",
    "    return re.sub('[?!,.]', '', text)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def overlap(a, b):\n",
    "    # remove stopwords\n",
    "    a = set(a) - stop_words\n",
    "    b = set(b) - stop_words\n",
    "    # TODO: fraction?\n",
    "    return len(a & b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps = []\n",
    "\n",
    "with open(\"../squad2/dev-v2.0.json\") as fp:\n",
    "    train = json.load(fp)\n",
    "for i in train['data']:\n",
    "    for j in i['paragraphs']:\n",
    "        # one context\n",
    "        context = j['context']\n",
    "        for k in j['qas']:\n",
    "            # one question\n",
    "            question = k['question']\n",
    "            if not k['answers']: continue\n",
    "            answer = hood(context, k['answers'][0]['answer_start'])\n",
    "            if not answer: continue\n",
    "            #print(answer)\n",
    "            o = overlap(tokenize(question), tokenize(answer))\n",
    "            overlaps.append((o, question, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411\n",
      "Mean: 2, Max: 15 overlap\n"
     ]
    }
   ],
   "source": [
    "print(sum(1 for i in overlaps if i[0] == 0))\n",
    "print(\"Mean: %d, Max: %d overlap\" % (np.mean([o[0] for o in overlaps]), np.max([o[0] for o in overlaps])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'What religion were the Normans', ' spirit and eventually for their Christian piety becoming exponents of the Catholic orthodoxy into which they assimilated They adopted the Gallo-Romance'), (0, 'What is the original meaning of the word Norman?', ' or Nordmannus (recorded in Medieval Latin 9th century) to mean \"Norseman')]\n"
     ]
    }
   ],
   "source": [
    "print([o for o in overlaps if o[0] == 0][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bolo ich 14 807 s nulovym overlapom +-40 chars, ale bacha - slova mali rovnake lemmy, preto lemmatizujem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "def stem(seq):\n",
    "    stemmer = LancasterStemmer()\n",
    "    return [stemmer.stem(word) for word in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps_lemma = []\n",
    "\n",
    "with open(\"../squad2/dev-v2.0.json\") as fp:\n",
    "    train = json.load(fp)\n",
    "for ii, i in enumerate(train['data']):\n",
    "    for jj, j in enumerate(i['paragraphs']):\n",
    "        # one context\n",
    "        context = j['context']\n",
    "        for kk, k in enumerate(j['qas']):\n",
    "            # one question\n",
    "            question = k['question']\n",
    "            if not k['answers']: continue\n",
    "            answer = hood(context, k['answers'][0]['answer_start'])\n",
    "            if not answer: continue\n",
    "            #print(answer)\n",
    "            o = overlap(stem(tokenize(question)), stem(tokenize(answer)))\n",
    "            overlaps_lemma.append((o, question, answer, (ii, jj, kk)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 3, Max: 11 overlap\n",
      "Mean tokens: 14\n",
      "218\n",
      "193\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean: %d, Max: %d overlap\" % (np.mean([o[0] for o in overlaps_lemma]), np.max([o[0] for o in overlaps_lemma])))\n",
    "print(\"Mean tokens: %d\" % np.mean([len(set(tokenize(o[2])) - stop_words) for o in overlaps_lemma]))\n",
    "print(sum(1 for i in overlaps_lemma if i[0] == 0))\n",
    "print(sum(1 for i in overlaps_lemma if i[0] > 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'What religion were the Normans', ' spirit and eventually for their Christian piety becoming exponents of the Catholic orthodoxy into which they assimilated They adopted the Gallo-Romance', (0, 1, 2)), (0, \"Who ruined Roussel de Bailleul's plans for an independent state?\", ' support from the local population but he was stopped by the Byzantine general Alexius', (0, 8, 2))]\n"
     ]
    }
   ],
   "source": [
    "print([o for o in overlaps_lemma if o[0] == 0][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10, 'The term \"southern\" California usually refers to how many of the southern-most counties of the state?', ' and southern California) the term \"southern California\" usually refers to the ten southern-most counties of the state This definition coincides neatly with', (2, 9, 2)), (10, 'What was the one linear HD channel Virgin Media carried from November 2006 to July 2009?', ' 30 November 2006 until 30 July 2009 it only carried one linear HD channel BBC HD after the conclusion of the ITV HD trial Virgin Media has claimed that', (3, 18, 3))]\n"
     ]
    }
   ],
   "source": [
    "print([o for o in overlaps_lemma if o[0] == 10][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make a dataset of them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4914\n"
     ]
    }
   ],
   "source": [
    "print(len(overlaps_lemma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect datasets with:\n",
    "- minimal overlap\n",
    "- maximal overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "low_overlap = [o[-1] for o in overlaps_lemma if o[0] == 0]\n",
    "big_overlap = [o[-1] for o in overlaps_lemma if o[0] > 6]\n",
    "\n",
    "\n",
    "with open(\"../squad2/dev-v2.0.json\") as fp:\n",
    "    train = json.load(fp)\n",
    "\n",
    "easy_dataset = {\"version\": train['version'], \"data\": []}\n",
    "hard_dataset = {\"version\": train['version'], \"data\": []}\n",
    "\n",
    "def add_to(dataset, topic, para, qa):\n",
    "    if not dataset['data'] or (dataset['data'][-1]['title'] != topic['title']):\n",
    "        # add context\n",
    "        dataset['data'].append({\"title\": topic['title'], \"paragraphs\": []})\n",
    "    if not dataset['data'][-1]['paragraphs'] or dataset['data'][-1]['paragraphs'][-1]['context'] != para['context']:\n",
    "        dataset['data'][-1]['paragraphs'].append({\"context\": para['context'], \"qas\": []})\n",
    "    if not dataset['data'][-1]['paragraphs'][-1]['qas'] or dataset['data'][-1]['paragraphs'][-1]['qas'][-1]['question'] != qa['question']:\n",
    "        dataset['data'][-1]['paragraphs'][-1]['qas'].append(qa)\n",
    "\n",
    "for ii, i in enumerate(train['data']):\n",
    "    for jj, j in enumerate(i['paragraphs']):\n",
    "        # one context\n",
    "        context = j['context']\n",
    "        for kk, k in enumerate(j['qas']):\n",
    "            # one question\n",
    "            if (ii, jj, kk) in low_overlap:\n",
    "                add_to(hard_dataset, i, j, k)\n",
    "            if (ii, jj, kk) in big_overlap:\n",
    "                add_to(easy_dataset, i, j, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test-en-easy.json\", \"w\") as fp:\n",
    "    json.dump(easy_dataset, fp)\n",
    "with open(\"test-en-hard.json\", \"w\") as fp:\n",
    "    json.dump(hard_dataset, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if similar for translated test-de-easy and test-de-hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- ENGLISH EASY DATASET --\n",
      "Mean: 7, Max: 11 overlap\n",
      "Mean tokens: 15\n",
      "0\n",
      "193\n"
     ]
    }
   ],
   "source": [
    "overlaps_lemma = []\n",
    "\n",
    "with open(\"test-en-easy.json\") as fp:\n",
    "    train = json.load(fp)\n",
    "for ii, i in enumerate(train['data']):\n",
    "    for jj, j in enumerate(i['paragraphs']):\n",
    "        # one context\n",
    "        context = j['context']\n",
    "        for kk, k in enumerate(j['qas']):\n",
    "            # one question\n",
    "            question = k['question']\n",
    "            if not k['answers']: continue\n",
    "            answer = hood(context, k['answers'][0]['answer_start'])\n",
    "            if not answer: continue\n",
    "            #print(answer)\n",
    "            o = overlap(stem(tokenize(question)), stem(tokenize(answer)))\n",
    "            overlaps_lemma.append((o, question, answer, (ii, jj, kk)))\n",
    "\n",
    "print(\"-- ENGLISH EASY DATASET --\")\n",
    "print(\"Mean: %d, Max: %d overlap\" % (np.mean([o[0] for o in overlaps_lemma]), np.max([o[0] for o in overlaps_lemma])))\n",
    "print(\"Mean tokens: %d\" % np.mean([len(set(tokenize(o[2])) - stop_words) for o in overlaps_lemma]))\n",
    "print(sum(1 for i in overlaps_lemma if i[0] == 0))\n",
    "print(sum(1 for i in overlaps_lemma if i[0] > 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- GERMAN EASY DATASET --\n",
      "Mean: 6, Max: 13 overlap\n",
      "Mean tokens: 19\n",
      "3\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "overlaps_lemma = []\n",
    "\n",
    "with open(\"test-de-easy.json\") as fp:\n",
    "    train = json.load(fp)\n",
    "for ii, i in enumerate(train['data']):\n",
    "    for jj, j in enumerate(i['paragraphs']):\n",
    "        # one context\n",
    "        context = j['context']\n",
    "        for kk, k in enumerate(j['qas']):\n",
    "            # one question\n",
    "            question = k['question']\n",
    "            if not k['answers']: continue\n",
    "            answer = hood(context, k['answers'][0]['answer_start'])\n",
    "            if not answer: continue\n",
    "            #print(answer)\n",
    "            o = overlap(stem(tokenize(question)), stem(tokenize(answer)))\n",
    "            overlaps_lemma.append((o, question, answer, (ii, jj, kk)))\n",
    "\n",
    "print(\"-- GERMAN EASY DATASET --\")\n",
    "print(\"Mean: %d, Max: %d overlap\" % (np.mean([o[0] for o in overlaps_lemma]), np.max([o[0] for o in overlaps_lemma])))\n",
    "print(\"Mean tokens: %d\" % np.mean([len(set(tokenize(o[2])) - stop_words) for o in overlaps_lemma]))\n",
    "print(sum(1 for i in overlaps_lemma if i[0] == 0))\n",
    "print(sum(1 for i in overlaps_lemma if i[0] > 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- ENGLISH HARD DATASET --\n",
      "Mean: 0, Max: 0 overlap\n",
      "Mean tokens: 14\n",
      "218\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "overlaps_lemma = []\n",
    "\n",
    "with open(\"test-en-hard.json\") as fp:\n",
    "    train = json.load(fp)\n",
    "for ii, i in enumerate(train['data']):\n",
    "    for jj, j in enumerate(i['paragraphs']):\n",
    "        # one context\n",
    "        context = j['context']\n",
    "        for kk, k in enumerate(j['qas']):\n",
    "            # one question\n",
    "            question = k['question']\n",
    "            if not k['answers']: continue\n",
    "            answer = hood(context, k['answers'][0]['answer_start'])\n",
    "            if not answer: continue\n",
    "            #print(answer)\n",
    "            o = overlap(stem(tokenize(question)), stem(tokenize(answer)))\n",
    "            overlaps_lemma.append((o, question, answer, (ii, jj, kk)))\n",
    "\n",
    "print(\"-- ENGLISH HARD DATASET --\")\n",
    "print(\"Mean: %d, Max: %d overlap\" % (np.mean([o[0] for o in overlaps_lemma]), np.max([o[0] for o in overlaps_lemma])))\n",
    "print(\"Mean tokens: %d\" % np.mean([len(set(tokenize(o[2])) - stop_words) for o in overlaps_lemma]))\n",
    "print(sum(1 for i in overlaps_lemma if i[0] == 0))\n",
    "print(sum(1 for i in overlaps_lemma if i[0] > 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- GERMAN HARD DATASET --\n",
      "Mean: 0, Max: 5 overlap\n",
      "Mean tokens: 18\n",
      "76\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "overlaps_lemma = []\n",
    "\n",
    "with open(\"test-de-hard.json\") as fp:\n",
    "    train = json.load(fp)\n",
    "for ii, i in enumerate(train['data']):\n",
    "    for jj, j in enumerate(i['paragraphs']):\n",
    "        # one context\n",
    "        context = j['context']\n",
    "        for kk, k in enumerate(j['qas']):\n",
    "            # one question\n",
    "            question = k['question']\n",
    "            if not k['answers']: continue\n",
    "            answer = hood(context, k['answers'][0]['answer_start'])\n",
    "            if not answer: continue\n",
    "            #print(answer)\n",
    "            o = overlap(stem(tokenize(question)), stem(tokenize(answer)))\n",
    "            overlaps_lemma.append((o, question, answer, (ii, jj, kk)))\n",
    "\n",
    "print(\"-- GERMAN HARD DATASET --\")\n",
    "print(\"Mean: %d, Max: %d overlap\" % (np.mean([o[0] for o in overlaps_lemma]), np.max([o[0] for o in overlaps_lemma])))\n",
    "print(\"Mean tokens: %d\" % np.mean([len(set(tokenize(o[2])) - stop_words) for o in overlaps_lemma]))\n",
    "print(sum(1 for i in overlaps_lemma if i[0] == 0))\n",
    "print(sum(1 for i in overlaps_lemma if i[0] > 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_from_file(file, lang='de'):\n",
    "    \n",
    "    if lang == 'de':\n",
    "        paragraph_key = \"Absatz\"\n",
    "        question_key = \"Frage\"\n",
    "        answer_key = \"Mogliche antwort\"\n",
    "    elif lang == 'en':\n",
    "        paragraph_key = \"Paragraph\"\n",
    "        question_key = \"Question\"\n",
    "        answer_key = \"Possible answer\"\n",
    "    \n",
    "    with open(file + \".json\") as fp:\n",
    "        train = json.load(fp)\n",
    "\n",
    "    doc = []\n",
    "\n",
    "    for ii, i in enumerate(train['data']):\n",
    "        doc.append(\"<h2>%s</h2>\\n\" % i['title'])\n",
    "        for jj, j in enumerate(i['paragraphs']):\n",
    "            doc.append(\"<h3>%s %d.%d</h3>\\n\" % (paragraph_key, ii, jj))\n",
    "            # one context\n",
    "            context = j['context']\n",
    "            doc.append(\"<p>%s</p><br>\\n\" % context)\n",
    "            doc.append(\"<table border=\\\"1\\\">\\n\")\n",
    "            for kk, k in enumerate(j['qas']):\n",
    "                # one question\n",
    "                question = k['question']\n",
    "                doc.append(\"<tr><td>%s</td><td>%s</td></tr>\\n\" % (question_key, question))\n",
    "                if not k['answers']: continue\n",
    "                answers = k['answers']\n",
    "                for answer in answers:\n",
    "                    doc.append(\"<tr><td>%s</td><td>%s</td></tr>\\n\" % (answer_key, answer['text']))\n",
    "            doc.append(\"</table>\\n\")\n",
    "            doc.append(\"<hr>\\n\")\n",
    "\n",
    "    doc = \"\".join(doc)\n",
    "    \n",
    "    with open(file + \"-in.html\", \"w\") as fp:\n",
    "        fp.write(\"<html>\\n<body>\\n\" + doc + \"</body>\\n</html>\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_from_file(\"test-de-easy\")\n",
    "html_from_file(\"test-de-hard\")\n",
    "html_from_file(\"test-en-easy\", 'en')\n",
    "html_from_file(\"test-en-hard\", 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
